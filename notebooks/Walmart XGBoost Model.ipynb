{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPwMscI+VaD/ZuY0dG5lab5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"FMXItjJLql6G"},"outputs":[],"source":["import os\n","import zipfile\n","import logging\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","from xgboost import XGBRegressor\n","from google.colab import files\n","\n","# Set logging level\n","logging.getLogger().setLevel(logging.WARNING)\n","\n","# Upload the dataset\n","uploaded = files.upload()\n","\n","# Load data\n","df = pd.read_csv(\"Walmart_Sales.csv\")\n","\n","# Parse dates and create time features\n","df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n","df['store'] = df['Store'].astype(str)\n","df = df.rename(columns={'Date': 'ds', 'Weekly_Sales': 'y'})\n","df = df.sort_values('ds')\n","\n","# Create time-based features\n","df['year'] = df['ds'].dt.year\n","df['month'] = df['ds'].dt.month\n","df['week'] = df['ds'].dt.isocalendar().week.astype(int)\n","df['dayofweek'] = df['ds'].dt.dayofweek\n","\n","# Create lag features function\n","def create_lag_features(store_df, lags=[1, 2, 4, 12]):\n","    store_df = store_df.sort_values('ds').copy()\n","    for lag in lags:\n","        store_df[f'lag_{lag}'] = store_df['y'].shift(lag)\n","    return store_df\n","\n","# Generate lag features per store\n","df_lagged = df.groupby('store').apply(create_lag_features).reset_index(drop=True)\n","df_lagged = df_lagged.dropna()\n","\n","# Define regressors\n","regressors = ['Holiday_Flag', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment',\n","              'year', 'month', 'week', 'dayofweek'] + [f'lag_{l}' for l in [1, 2, 4, 12]]\n","\n","# Train/test split dates\n","start_date = df_lagged['ds'].min()\n","train_end_date = start_date + pd.DateOffset(years=2)\n","\n","store_metrics = []\n","store_forecasts = []\n","\n","# Create directory for plots\n","output_dir = \"xgb_store_forecasts\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","future_periods = 12  # Next 12 weeks forecast\n","\n","for store in df_lagged['store'].unique():\n","    store_df = df_lagged[df_lagged['store'] == store].copy()\n","    train_df = store_df[store_df['ds'] < train_end_date]\n","    test_df = store_df[store_df['ds'] >= train_end_date]\n","\n","    X_train = train_df[regressors]\n","    y_train = train_df['y']\n","    X_test = test_df[regressors]\n","    y_test = test_df['y']\n","\n","    model = XGBRegressor(n_estimators=100, learning_rate=0.1)\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","\n","    mae = mean_absolute_error(y_test, y_pred)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n","\n","    print(f\"Store {store} - MAE: {mae:.2f}, RMSE: {rmse:.2f}, MAPE: {mape:.2f}%\")\n","\n","    results = test_df[['ds', 'y']].copy()\n","    results['yhat'] = y_pred\n","    results['store'] = store\n","    store_forecasts.append(results)\n","\n","    store_metrics.append({'store': store, 'mae': mae, 'rmse': rmse, 'mape': mape})\n","\n","    # === Future prediction with lag feature update ===\n","    last_known = store_df[store_df['ds'] <= test_df['ds'].max()].copy()\n","    last_known = last_known.sort_values('ds')\n","\n","    future_dates = pd.date_range(start=last_known['ds'].max() + pd.Timedelta(weeks=1), periods=future_periods, freq='W')\n","\n","    future_rows = []\n","\n","    # We'll keep a DataFrame to hold the rolling lags for future predictions\n","    extended_df = last_known.copy()\n","\n","    for date in future_dates:\n","        # Create new row dict\n","        new_row = {'ds': date, 'store': store}\n","\n","        # For time features\n","        new_row['year'] = date.year\n","        new_row['month'] = date.month\n","        new_row['week'] = date.isocalendar().week\n","        new_row['dayofweek'] = date.dayofweek\n","\n","        # Regressors assumed constant - take from last known row\n","        for reg in ['Holiday_Flag', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']:\n","            # If you have a time series or model for these regressors, replace this with predictions\n","            # Otherwise, just use the last known value\n","            new_row[reg] = extended_df.iloc[-1][reg]\n","\n","        # Calculate lag features based on extended_df\n","        for lag in [1, 2, 4, 12]:\n","            lag_date = date - pd.Timedelta(weeks=lag)\n","            lag_val = extended_df[extended_df['ds'] == lag_date]['y']\n","            if not lag_val.empty:\n","                new_row[f'lag_{lag}'] = lag_val.values[0]\n","            else:\n","                # If lag value not available (e.g. beyond known dates), fill with mean or 0\n","                new_row[f'lag_{lag}'] = extended_df['y'].mean()\n","\n","        # Convert new_row to DataFrame to feed model\n","        new_df = pd.DataFrame([new_row])\n","        # Predict yhat\n","        yhat = model.predict(new_df[regressors])[0]\n","        new_row['y'] = yhat  # Save predicted value\n","\n","        # Append new_row to extended_df for next iterations lag calculations\n","        extended_df = pd.concat([extended_df, pd.DataFrame([new_row])], ignore_index=True)\n","\n","        future_rows.append(new_row)\n","\n","    future_df = pd.DataFrame(future_rows)\n","\n","    # Append future_df to store_forecasts (rename 'y' to 'yhat' for consistency)\n","    store_forecasts.append(future_df[['ds', 'y']].rename(columns={'y': 'yhat'}).assign(store=store))\n","\n","    # === Plotting ===\n","    full_store_df = df[df['store'] == store]\n","    plt.figure(figsize=(12, 6))\n","    plt.plot(full_store_df['ds'], full_store_df['y'], label='Actual')\n","    plt.plot(results['ds'], results['yhat'], label='XGBoost Forecast (Test)')\n","    plt.plot(future_df['ds'], future_df['y'], label='XGBoost Forecast (Future)', linestyle='--')\n","\n","    plt.title(f'XGBoost Walmart Store {store} Forecast')\n","    plt.xlabel('Date')\n","    plt.ylabel('Weekly Sales')\n","    plt.legend()\n","\n","    # Add metrics textbox\n","    metrics_text = (f\"MAE: {mae:.2f}\\n\"\n","                    f\"RMSE: {rmse:.2f}\\n\"\n","                    f\"MAPE: {mape:.2f}%\")\n","    plt.gca().text(0.02, 0.95, metrics_text, transform=plt.gca().transAxes,\n","                   fontsize=10, verticalalignment='top',\n","                   bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"white\", alpha=0.7))\n","\n","    plt.tight_layout()\n","    plt.savefig(f\"{output_dir}/xgb_store_{store}_forecast.png\")\n","    plt.close()\n","\n","        # Prepare backtest export CSV\n","    backtest_export = results[['ds', 'y', 'yhat']].copy()\n","    backtest_export['store'] = store\n","    backtest_export['type'] = 'backtest'\n","\n","    # Prepare future export CSV\n","    future_export = future_df[['ds', 'y']].rename(columns={'y': 'yhat'}).copy()\n","    future_export['y'] = np.nan  # no actual values for future\n","    future_export['store'] = store\n","    future_export['type'] = 'future'\n","\n","    # Combine backtest and future\n","    export_df = pd.concat([backtest_export, future_export], ignore_index=True)\n","\n","    # Rename columns for Tableau friendliness\n","    export_df.rename(columns={\n","        'ds': 'date',\n","        'y': 'actual_revenue',\n","        'yhat': 'forecast_revenue'\n","    }, inplace=True)\n","\n","    # Save CSV\n","    csv_filename = f'{output_dir}/xgb_store_{store}_forecast.csv'\n","    export_df.to_csv(csv_filename, index=False)\n","\n","# Combine all forecasts\n","all_forecasts = pd.concat(store_forecasts)\n","\n","# Overall metrics\n","overall_mae = np.mean([m['mae'] for m in store_metrics])\n","overall_rmse = np.mean([m['rmse'] for m in store_metrics])\n","overall_mape = np.mean([m['mape'] for m in store_metrics])\n","\n","print(f\"\\nOverall XGBoost Metrics Across Stores:\")\n","print(f\"MAE: {overall_mae:.2f}\")\n","print(f\"RMSE: {overall_rmse:.2f}\")\n","print(f\"MAPE: {overall_mape:.2f}%\")\n","\n","# Zip the plot folder\n","zip_filename = \"xgb_store_forecasts.zip\"\n","with zipfile.ZipFile(zip_filename, 'w') as zipf:\n","    for root, dirs, files in os.walk(output_dir):\n","        for file in files:\n","            zipf.write(os.path.join(root, file), arcname=file)\n","\n","print(f\"Forecast plots saved in '{output_dir}' and zipped as '{zip_filename}'.\")\n","\n","# Add CSV files to the zip as well\n","with zipfile.ZipFile(zip_filename, 'a') as zipf:\n","    for root, dirs, files in os.walk(output_dir):\n","        for file in files:\n","            if file.endswith('.csv'):\n","                zipf.write(os.path.join(root, file), arcname=file)\n","\n","print(f\"Forecast CSV files saved alongside plots and zipped as '{zip_filename}'.\")"]}]}